{"version":3,"sources":["../../src/features/aiTextSplitter.js"],"sourcesContent":["import { Types, InvalidConfiguration, ValidationError } from '@kitmi/types';\nimport Feature from '../Feature';\n\nfunction findBestSeparator(text, separators) {\n    for (let separator of separators) {\n        const index = text.lastIndexOf(separator);\n        if (index !== -1) {\n            return index + separator.length;\n        }\n    }\n    return -1;\n}\n\nfunction findEnd(s, start, maxBytes) {\n    let low = start;\n    let high = s.length;\n\n    while (low < high) {\n        let mid = Math.floor((low + high + 1) / 2);\n        let substring = s.substring(start, mid);\n        let bytes = Buffer.byteLength(substring, 'utf8');\n\n        if (bytes > maxBytes) {\n            high = mid - 1;\n        } else {\n            low = mid;\n        }\n    }\n\n    return low;\n}\n\nexport default {\n    stage: Feature.SERVICE,\n\n    groupable: true,\n\n    packages: ['tiktoken'],\n\n    load_: async function (app, options, name) {\n        const {\n            chunkSize,\n            maxChunkOverlap,\n            overlapSeparators,\n            encodingForModel: _encodingForModel,\n        } = app.featureConfig(\n            options ?? {},\n            {\n                schema: {\n                    chunkSize: { type: 'integer', default: 4095 },\n                    maxChunkOverlap: { type: 'integer', default: 100 },\n                    overlapSeparators: {\n                        type: 'array',\n                        element: { type: 'text' },\n                        default: ['\\n\\n', '\\n', '。', '.', '！', '!', '？', '?', '；', ';', '，', ',', ' '],\n                    },\n                    encodingForModel: {\n                        type: 'text',\n                        enum: ['text-embedding-ada-002', 'gpt-3.5-turbo', 'gpt-4'],\n                    },\n                },\n            },\n            name\n        );\n\n        if (maxChunkOverlap > chunkSize) {\n            throw new InvalidConfiguration(\n                'maxChunkOverlap must be less than chunkSize',\n                app,\n                'aiTextSplitter.maxChunkOverlap'\n            );\n        }\n\n        const { encoding_for_model } = await app.tryRequire_('tiktoken');\n\n        let tokenizer = encoding_for_model(_encodingForModel);\n        const textDecoder = new TextDecoder();\n\n        app.on('stopping', async () => {\n            tokenizer.free();\n            tokenizer = null;\n        });\n\n        const service = {\n            peek: (text, _chunkSize) => {\n                return textDecoder.decode(tokenizer.decode(tokenizer.encode(text).slice(0, _chunkSize ?? chunkSize)));\n            },\n\n            split: (text, chunkHeaderOptions) => {\n                const {\n                    chunkSize: __chunkSize,\n                    maxChunkOverlap: _maxChunkOverlap,\n                    chunkHeader,\n                    chunkOverlapHeader,\n                    appendChunkOverlapHeader,\n                } = Types.OBJECT.sanitize(chunkHeaderOptions ?? {}, {\n                    schema: {\n                        chunkSize: { type: 'integer', default: chunkSize },\n                        maxChunkOverlap: {\n                            type: 'integer',\n                            default: maxChunkOverlap,\n                        },\n                        chunkHeader: { type: 'text', default: '' },\n                        chunkOverlapHeader: {\n                            type: 'text',\n                            default: \"(cont'd) \",\n                        },\n                        appendChunkOverlapHeader: {\n                            type: 'boolean',\n                            default: false,\n                        },\n                    },\n                });\n\n                const chunks = [];\n                let remainingTokens = tokenizer.encode(text);\n                let _chunkSize = __chunkSize - chunkHeader.length;\n                const _chunkSize2 = appendChunkOverlapHeader ? _chunkSize - chunkOverlapHeader.length : _chunkSize;\n\n                if (_chunkSize2 < _maxChunkOverlap) {\n                    throw new ValidationError('\"chunkHeader\" or \"chunkOverlapHeader\" too long', {\n                        chunkHeader,\n                        chunkOverlapHeader,\n                        appendChunkOverlapHeader,\n                        chunkSize: __chunkSize,\n                        maxChunkOverlap: _maxChunkOverlap,\n                    });\n                }\n\n                let _chunkHeader = chunkHeader;\n                const _chunkHeader2 = appendChunkOverlapHeader ? chunkHeader + chunkOverlapHeader : chunkHeader;\n\n                while (remainingTokens.length > 0) {\n                    let chunkEnd = _chunkSize;\n                    let content = _chunkHeader;\n\n                    if (remainingTokens.length > _chunkSize) {\n                        const overlapStart = _chunkSize - _maxChunkOverlap;\n                        const overlapTokens = remainingTokens.slice(overlapStart, _chunkSize);\n                        const overlapText = textDecoder.decode(tokenizer.decode(overlapTokens));\n\n                        const bestSeparatorInOverlap = findBestSeparator(overlapText, overlapSeparators);\n                        if (bestSeparatorInOverlap !== -1) {\n                            chunkEnd =\n                                overlapStart + tokenizer.encode(overlapText.slice(0, bestSeparatorInOverlap)).length;\n                        }\n                    }\n                    chunks.push(content + textDecoder.decode(tokenizer.decode(remainingTokens.slice(0, chunkEnd))));\n                    remainingTokens = remainingTokens.slice(chunkEnd);\n\n                    if (appendChunkOverlapHeader) {\n                        _chunkSize = _chunkSize2;\n                        _chunkHeader = _chunkHeader2;\n                    }\n                }\n\n                return chunks;\n            },\n\n            splitByBytes: (text, maxBytes) => {\n                let chunks = [];\n\n                let start = 0;\n                while (start < text.length) {\n                    let end = findEnd(text, start, maxBytes);\n                    chunks.push(text.substring(start, end));\n                    start = end;\n                }\n\n                return chunks;\n            },\n        };\n\n        app.registerService(name, service);\n    },\n};\n"],"names":["findBestSeparator","text","separators","separator","index","lastIndexOf","length","findEnd","s","start","maxBytes","low","high","mid","Math","floor","substring","bytes","Buffer","byteLength","stage","Feature","SERVICE","groupable","packages","load_","app","options","name","chunkSize","maxChunkOverlap","overlapSeparators","encodingForModel","_encodingForModel","featureConfig","schema","type","default","element","enum","InvalidConfiguration","encoding_for_model","tryRequire_","tokenizer","textDecoder","TextDecoder","on","free","service","peek","_chunkSize","decode","encode","slice","split","chunkHeaderOptions","__chunkSize","_maxChunkOverlap","chunkHeader","chunkOverlapHeader","appendChunkOverlapHeader","Types","OBJECT","sanitize","chunks","remainingTokens","_chunkSize2","ValidationError","_chunkHeader","_chunkHeader2","chunkEnd","content","overlapStart","overlapTokens","overlapText","bestSeparatorInOverlap","push","splitByBytes","end","registerService"],"mappings":";;;;+BAgCA;;;eAAA;;;uBAhC6D;gEACzC;;;;;;AAEpB,SAASA,kBAAkBC,IAAI,EAAEC,UAAU;IACvC,KAAK,IAAIC,aAAaD,WAAY;QAC9B,MAAME,QAAQH,KAAKI,WAAW,CAACF;QAC/B,IAAIC,UAAU,CAAC,GAAG;YACd,OAAOA,QAAQD,UAAUG,MAAM;QACnC;IACJ;IACA,OAAO,CAAC;AACZ;AAEA,SAASC,QAAQC,CAAC,EAAEC,KAAK,EAAEC,QAAQ;IAC/B,IAAIC,MAAMF;IACV,IAAIG,OAAOJ,EAAEF,MAAM;IAEnB,MAAOK,MAAMC,KAAM;QACf,IAAIC,MAAMC,KAAKC,KAAK,CAAC,AAACJ,CAAAA,MAAMC,OAAO,CAAA,IAAK;QACxC,IAAII,YAAYR,EAAEQ,SAAS,CAACP,OAAOI;QACnC,IAAII,QAAQC,OAAOC,UAAU,CAACH,WAAW;QAEzC,IAAIC,QAAQP,UAAU;YAClBE,OAAOC,MAAM;QACjB,OAAO;YACHF,MAAME;QACV;IACJ;IAEA,OAAOF;AACX;MAEA,WAAe;IACXS,OAAOC,gBAAO,CAACC,OAAO;IAEtBC,WAAW;IAEXC,UAAU;QAAC;KAAW;IAEtBC,OAAO,eAAgBC,GAAG,EAAEC,OAAO,EAAEC,IAAI;QACrC,MAAM,EACFC,SAAS,EACTC,eAAe,EACfC,iBAAiB,EACjBC,kBAAkBC,iBAAiB,EACtC,GAAGP,IAAIQ,aAAa,CACjBP,WAAW,CAAC,GACZ;YACIQ,QAAQ;gBACJN,WAAW;oBAAEO,MAAM;oBAAWC,SAAS;gBAAK;gBAC5CP,iBAAiB;oBAAEM,MAAM;oBAAWC,SAAS;gBAAI;gBACjDN,mBAAmB;oBACfK,MAAM;oBACNE,SAAS;wBAAEF,MAAM;oBAAO;oBACxBC,SAAS;wBAAC;wBAAQ;wBAAM;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;wBAAK;qBAAI;gBAClF;gBACAL,kBAAkB;oBACdI,MAAM;oBACNG,MAAM;wBAAC;wBAA0B;wBAAiB;qBAAQ;gBAC9D;YACJ;QACJ,GACAX;QAGJ,IAAIE,kBAAkBD,WAAW;YAC7B,MAAM,IAAIW,2BAAoB,CAC1B,+CACAd,KACA;QAER;QAEA,MAAM,EAAEe,kBAAkB,EAAE,GAAG,MAAMf,IAAIgB,WAAW,CAAC;QAErD,IAAIC,YAAYF,mBAAmBR;QACnC,MAAMW,cAAc,IAAIC;QAExBnB,IAAIoB,EAAE,CAAC,YAAY;YACfH,UAAUI,IAAI;YACdJ,YAAY;QAChB;QAEA,MAAMK,UAAU;YACZC,MAAM,CAAChD,MAAMiD;gBACT,OAAON,YAAYO,MAAM,CAACR,UAAUQ,MAAM,CAACR,UAAUS,MAAM,CAACnD,MAAMoD,KAAK,CAAC,GAAGH,cAAcrB;YAC7F;YAEAyB,OAAO,CAACrD,MAAMsD;gBACV,MAAM,EACF1B,WAAW2B,WAAW,EACtB1B,iBAAiB2B,gBAAgB,EACjCC,WAAW,EACXC,kBAAkB,EAClBC,wBAAwB,EAC3B,GAAGC,YAAK,CAACC,MAAM,CAACC,QAAQ,CAACR,sBAAsB,CAAC,GAAG;oBAChDpB,QAAQ;wBACJN,WAAW;4BAAEO,MAAM;4BAAWC,SAASR;wBAAU;wBACjDC,iBAAiB;4BACbM,MAAM;4BACNC,SAASP;wBACb;wBACA4B,aAAa;4BAAEtB,MAAM;4BAAQC,SAAS;wBAAG;wBACzCsB,oBAAoB;4BAChBvB,MAAM;4BACNC,SAAS;wBACb;wBACAuB,0BAA0B;4BACtBxB,MAAM;4BACNC,SAAS;wBACb;oBACJ;gBACJ;gBAEA,MAAM2B,SAAS,EAAE;gBACjB,IAAIC,kBAAkBtB,UAAUS,MAAM,CAACnD;gBACvC,IAAIiD,aAAaM,cAAcE,YAAYpD,MAAM;gBACjD,MAAM4D,cAAcN,2BAA2BV,aAAaS,mBAAmBrD,MAAM,GAAG4C;gBAExF,IAAIgB,cAAcT,kBAAkB;oBAChC,MAAM,IAAIU,sBAAe,CAAC,kDAAkD;wBACxET;wBACAC;wBACAC;wBACA/B,WAAW2B;wBACX1B,iBAAiB2B;oBACrB;gBACJ;gBAEA,IAAIW,eAAeV;gBACnB,MAAMW,gBAAgBT,2BAA2BF,cAAcC,qBAAqBD;gBAEpF,MAAOO,gBAAgB3D,MAAM,GAAG,EAAG;oBAC/B,IAAIgE,WAAWpB;oBACf,IAAIqB,UAAUH;oBAEd,IAAIH,gBAAgB3D,MAAM,GAAG4C,YAAY;wBACrC,MAAMsB,eAAetB,aAAaO;wBAClC,MAAMgB,gBAAgBR,gBAAgBZ,KAAK,CAACmB,cAActB;wBAC1D,MAAMwB,cAAc9B,YAAYO,MAAM,CAACR,UAAUQ,MAAM,CAACsB;wBAExD,MAAME,yBAAyB3E,kBAAkB0E,aAAa3C;wBAC9D,IAAI4C,2BAA2B,CAAC,GAAG;4BAC/BL,WACIE,eAAe7B,UAAUS,MAAM,CAACsB,YAAYrB,KAAK,CAAC,GAAGsB,yBAAyBrE,MAAM;wBAC5F;oBACJ;oBACA0D,OAAOY,IAAI,CAACL,UAAU3B,YAAYO,MAAM,CAACR,UAAUQ,MAAM,CAACc,gBAAgBZ,KAAK,CAAC,GAAGiB;oBACnFL,kBAAkBA,gBAAgBZ,KAAK,CAACiB;oBAExC,IAAIV,0BAA0B;wBAC1BV,aAAagB;wBACbE,eAAeC;oBACnB;gBACJ;gBAEA,OAAOL;YACX;YAEAa,cAAc,CAAC5E,MAAMS;gBACjB,IAAIsD,SAAS,EAAE;gBAEf,IAAIvD,QAAQ;gBACZ,MAAOA,QAAQR,KAAKK,MAAM,CAAE;oBACxB,IAAIwE,MAAMvE,QAAQN,MAAMQ,OAAOC;oBAC/BsD,OAAOY,IAAI,CAAC3E,KAAKe,SAAS,CAACP,OAAOqE;oBAClCrE,QAAQqE;gBACZ;gBAEA,OAAOd;YACX;QACJ;QAEAtC,IAAIqD,eAAe,CAACnD,MAAMoB;IAC9B;AACJ"}